package lt.ziniumanas.service.outsource;

import lt.ziniumanas.model.NewsSource;
import lt.ziniumanas.model.outsource.OutsourceArticleScrapingRule;
import lt.ziniumanas.model.outsource.OutsourceArticlePendingUrl;
import lt.ziniumanas.repository.NewsSourceRepository;
import lt.ziniumanas.repository.outsource.OutsourceArticleScrapingRuleRepository;
import lt.ziniumanas.repository.outsource.OutsourceArticlePendingUrlRepository;
import lt.ziniumanas.util.PendingArticleUrlTableSequenceResetUtil;

import org.jsoup.Jsoup;
import org.jsoup.nodes.Document;
import org.jsoup.nodes.Element;
import org.jsoup.select.Elements;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.stereotype.Service;

import java.util.HashSet;
import java.util.List;
import java.util.Set;

@Service
public class OutsourceArticlePendingUrlService {
    private static final Logger logger = LoggerFactory.getLogger(OutsourceArticlePendingUrlService.class);

    private final NewsSourceRepository newsSourceRepository;
    private final OutsourceArticleScrapingRuleRepository scrapingRuleRepository;
    private final OutsourceArticlePendingUrlRepository pendingUrlRepository;
    private final PendingArticleUrlTableSequenceResetUtil sequenceResetUtil; // <- pridƒóta

    public OutsourceArticlePendingUrlService(
            NewsSourceRepository newsSourceRepository,
            OutsourceArticleScrapingRuleRepository scrapingRuleRepository,
            OutsourceArticlePendingUrlRepository pendingUrlRepository,
            PendingArticleUrlTableSequenceResetUtil sequenceResetUtil // <- injekcija
    ) {
        this.newsSourceRepository = newsSourceRepository;
        this.scrapingRuleRepository = scrapingRuleRepository;
        this.pendingUrlRepository = pendingUrlRepository;
        this.sequenceResetUtil = sequenceResetUtil;
    }

    /**
     * Bendras metodas, kuris surenka straipsni≈≥ URL i≈° vis≈≥ ≈°altini≈≥ pagal j≈≥ taisykles.
     */


    /**
     * Programos u≈ækrovimo metu surenkame straipsni≈≥ nuorodas i≈° vis≈≥ ≈°altini≈≥.
     */

    public void collectArticleUrlsOnStart() {
        logger.info("üßπ Trinami seni ƒØra≈°ai ir restartuojama seka...");
        pendingUrlRepository.deleteAll();
        sequenceResetUtil.resetPendingUrlSequence(); // <- restartavimas
        logger.info("üåê Pradedamas URL surinkimas i≈° vis≈≥ ≈°altini≈≥...");
        collectUrlsFromAllSources();
        logger.info("Pradinis straipsni≈≥ URL surinkimas u≈æbaigtas.");
    }

    /**
     * Periodinis straipsni≈≥ URL surinkimas kas 30 min.
     */
    public void scheduleCollectArticleUrls() {
        logger.info("üïí Pusvalandinis straipsni≈≥ URL surinkimas...");
        collectUrlsFromAllSources(); // Kvietimas ƒØ bendrƒÖ metodƒÖ
        logger.info("Pusvalandinis straipsni≈≥ URL surinkimas u≈æbaigtas.");
    }

    private void collectUrlsFromAllSources() {
        List<NewsSource> sources = newsSourceRepository.findAll();
        for (NewsSource source : sources) {
            collectArticleUrls(source); // ≈†is metodas apdoroja kiekvienƒÖ ≈°altinƒØ
        }
    }
    /**
     * Metodas, kuris surenka straipsni≈≥ nuorodas pagal ≈°altinio taisykles.
     * @param source ≈†altinis, kurio URL ir taisyklƒós bus naudojamos.
     */
    private void collectArticleUrls(NewsSource source) {
        logger.info("üîç Tikrinamas ≈°altinis: {}", source.getSourceName());

        List<OutsourceArticleScrapingRule> rules = scrapingRuleRepository.findByNewsSourceId(source.getId());
        if (rules.isEmpty()) {
            logger.warn("‚ö†Ô∏è Nerasta scraping taisykli≈≥ ≈°altiniui: {}", source.getSourceName());
            return;
        }

        Set<String> foundUrls = new HashSet<>();

        for (OutsourceArticleScrapingRule rule : rules) {
            try {
                // Susiekimas su ≈°altiniu pagal jo URL ir HTML turinio gavimas
                Document doc = Jsoup.connect(source.getUrlAddress())
                        .userAgent("Mozilla/5.0")
                        .timeout(10000)
                        .get();

                // Pasirenkame straipsni≈≥ pavadinimus pagal title_selector
                Elements postTitles = doc.select(rule.getTitleSelector());

                // Iteruojame per rastus pavadinimus ir i≈°traukime straipsnio nuorodas
                for (Element postTitle : postTitles) {
                    Element linkElement = postTitle.selectFirst("a[href]"); // Randa pirmƒÖ <a> su href
                    if (linkElement != null) {
                        String url = linkElement.absUrl("href");
                        if (!url.isBlank() && foundUrls.add(url)) {
                            savePendingUrl(url, source);
                        }
                    }
                }

                logger.info("‚úÖ Rasta URL'≈≥ ≈°altiniui {}: {}", source.getSourceName(), foundUrls.size());

            } catch (Exception e) {
                logger.error("‚ùå Klaida renkant URL'ƒÖ i≈° {}: {}", source.getSourceName(), e.getMessage());
            }
        }
    }

    /**
     * Metodas, kuris i≈°saugo naujas straipsni≈≥ nuorodas ƒØ duomen≈≥ bazƒô.
     * @param url Straipsnio URL.
     * @param source ≈†altinis, i≈° kurio nuoroda buvo paimta.
     */
    private void savePendingUrl(String url, NewsSource source) {
        if (pendingUrlRepository.findByUrl(url).isEmpty()) {
            OutsourceArticlePendingUrl pending = OutsourceArticlePendingUrl.builder()
                    .url(url)
                    .newsSource(source)
                    .build();
            pendingUrlRepository.save(pending);
            logger.info("üíæ I≈°saugotas naujas URL: {}", url);
        } else {
            logger.debug("üîÅ URL jau egzistuoja: {}", url);
        }
    }
}
